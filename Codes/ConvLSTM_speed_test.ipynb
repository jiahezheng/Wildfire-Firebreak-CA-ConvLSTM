{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"muUUsUl5Brg3"},"outputs":[],"source":["import sys\n","import math\n","import random\n","import copy\n","\n","import pandas as pd\n","import numpy as np\n","\n","from tqdm import tqdm\n","import time\n","\n","import matplotlib.pyplot as plt\n","from matplotlib import cm\n","from matplotlib import animation as animation\n","\n","import matplotlib as mpl\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader\n","import os\n","\n","!pip install torchmetrics\n","from torchmetrics.image import StructuralSimilarityIndexMeasure\n","\n","from PIL import Image, ImageSequence\n","from skimage.transform import resize\n","\n","from skimage.metrics import structural_similarity as ssim\n","\n","import json\n","\n","directory = ''  # your directory\n","\n","# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"TMxAZF9_1ace"},"source":["#### model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7VZ5DUKCBcSH"},"outputs":[],"source":["class FireDataset(Dataset):\n","    def __init__(self, fire_data, seq_len):\n","        self.fire_data = fire_data\n","        shape = self.fire_data.shape\n","\n","        self.number = shape[0]\n","        self.time_step = shape[1]\n","        self.frame_len = shape[2]\n","        self.seq_len = seq_len\n","\n","    def __len__(self):\n","        return self.number* (self.time_step - self.seq_len +1)\n","\n","    def __getitem__(self, idx):\n","        idx0 = idx//(self.time_step - self.seq_len +1)\n","        idx1 = idx%(self.time_step - self.seq_len +1)\n","        input, target = torch.tensor(self.fire_data[idx0][idx1:idx1+3]),  torch.tensor(self.fire_data[idx0][idx1+3:idx1+6])\n","\n","        return  torch.stack((input, input), dim=1), target\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qGxL-ZPvBerW"},"outputs":[],"source":["class ConvLSTMCell(nn.Module):\n","  def __init__(self, input_dim, hidden_dim, kernel_size):\n","    super(ConvLSTMCell, self).__init__()\n","\n","    self.input_dim = input_dim\n","    self.hidden_dim = hidden_dim\n","    self.kernel_size = kernel_size\n","\n","    padding = kernel_size // 2\n","    self.conv = nn.Conv2d(in_channels=input_dim + hidden_dim,\n","                out_channels=4 * hidden_dim,\n","                kernel_size=kernel_size,\n","                padding=padding,\n","                bias=True)\n","\n","  def forward(self, input_tensor, cur_state):\n","    h_cur, c_cur = cur_state\n","\n","    combined = torch.cat([input_tensor, h_cur], dim=1)\n","    combined_conv = self.conv(combined)\n","\n","    cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n","\n","    i = torch.sigmoid(cc_i)\n","    f = torch.sigmoid(cc_f)\n","    o = torch.sigmoid(cc_o)\n","    g = torch.tanh(cc_g)\n","\n","    c_next = f * c_cur + i * g\n","    h_next = o * torch.tanh(c_next)\n","\n","    return h_next, c_next\n","\n","  def init_hidden(self, batch_size, image_size):\n","    height, width = image_size\n","    return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n","        torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mKKe4ZNBBem9"},"outputs":[],"source":["class EncoderDecoderConvLSTM(nn.Module):\n","  def __init__(self, input_dim, hidden_dim):\n","    super(EncoderDecoderConvLSTM, self).__init__()\n","\n","    self.encoder_1_convlstm = ConvLSTMCell(input_dim=input_dim, hidden_dim=hidden_dim, kernel_size=3)\n","    self.encoder_2_convlstm = ConvLSTMCell(input_dim=hidden_dim, hidden_dim=hidden_dim, kernel_size=3)\n","    self.decoder_1_convlstm = ConvLSTMCell(input_dim=hidden_dim, hidden_dim=hidden_dim, kernel_size=3)\n","    self.decoder_2_convlstm = ConvLSTMCell(input_dim=hidden_dim, hidden_dim=hidden_dim, kernel_size=3)\n","    self.decoder_CNN = nn.Conv3d(in_channels=hidden_dim, out_channels = 16 , kernel_size=(1, 3, 3), padding=(0, 1, 1))\n","\n","\n","  def autoencoder(self, x, seq_len, future_step, h_t, c_t, h_t2, c_t2, h_t3, c_t3, h_t4, c_t4):\n","\n","    outputs = []\n","\n","    # encoder\n","    for t in range(seq_len):\n","      h_t, c_t = self.encoder_1_convlstm(input_tensor=x[:, t, :, :], cur_state=[h_t, c_t])  # we could concat to provide skip conn here\n","      h_t2, c_t2 = self.encoder_2_convlstm(input_tensor=h_t, cur_state=[h_t2, c_t2])  # we could concat to provide skip conn here\n","\n","    # encoder_vector\n","    encoder_vector = h_t2\n","\n","    # decoder\n","    for t in range(future_step):\n","      h_t3, c_t3 = self.decoder_1_convlstm(input_tensor=encoder_vector, cur_state=[h_t3, c_t3])  # we could concat to provide skip conn here\n","      h_t4, c_t4 = self.decoder_2_convlstm(input_tensor=h_t3, cur_state=[h_t4, c_t4])  # we could concat to provide skip conn here\n","      encoder_vector = h_t4\n","      outputs += [h_t4]  # predictions\n","\n","    outputs = torch.stack(outputs, 1)\n","    outputs = outputs.permute(0, 2, 1, 3, 4)\n","    outputs = self.decoder_CNN(outputs)\n","    #outputs = outputs.permute(0, 2, 1, 3, 4)\n","\n","    return outputs\n","\n","  def forward(self, x, future_seq=3, hidden_state=None):\n","\n","    # find size of different input dimensions\n","    b, seq_len, _, h, w = x.size()\n","\n","    # initialize hidden states\n","    h_t, c_t = self.encoder_1_convlstm.init_hidden(batch_size=b, image_size=(h, w))\n","    h_t2, c_t2 = self.encoder_2_convlstm.init_hidden(batch_size=b, image_size=(h, w))\n","    h_t3, c_t3 = self.decoder_1_convlstm.init_hidden(batch_size=b, image_size=(h, w))\n","    h_t4, c_t4 = self.decoder_2_convlstm.init_hidden(batch_size=b, image_size=(h, w))\n","\n","    # autoencoder forward\n","    outputs = self.autoencoder(x, seq_len, future_seq, h_t, c_t, h_t2, c_t2, h_t3, c_t3, h_t4, c_t4)\n","\n","    return outputs\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Q3hvTHvBef9"},"outputs":[],"source":["def train_convLSTM(train_data, test=False, test_data=None):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    input_dim = 2\n","    hidden_dim = 128\n","    kernel_size = 3\n","    num_layers = 3\n","    seq_len = 3\n","\n","    model = EncoderDecoderConvLSTM(input_dim, hidden_dim).to(device)\n","\n","    criterion = nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=- 100, reduce=None, reduction='mean', label_smoothing=0.0)\n","    criterion2 = nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr=3e-4)\n","\n","    batch_size = 16\n","    iter = 5\n","\n","    fire_data_loader_train = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","\n","    if test:\n","        mse_list = []\n","        ssim_list = []\n","\n","    for it in range(iter):\n","        for batch_no, (batch_input, batch_target) in enumerate(fire_data_loader_train):\n","            model.train()\n","\n","            batch_input, batch_target = batch_input.to(device, dtype=torch.float32), batch_target.to(device, dtype=torch.int64)\n","\n","            optimizer.zero_grad()\n","\n","            logits = model(batch_input)\n","            \"\"\"if batch_no % 100 == 0:\n","                print(torch.unique(batch_input),torch.unique(batch_target),torch.unique(torch.argmax(logits, dim=1)))\"\"\"\n","            #print(f'logit shape{logits.shape}')\n","            train_loss = criterion(logits, batch_target)\n","\n","            train_loss.backward()\n","            optimizer.step()\n","\n","            \"\"\"if batch_no % 50 == 0:\n","                print('Batch:{:5d}  |  Train loss: {:.4f}'.format(batch_no, train_loss))\"\"\"\n","\n","            if test:\n","                if batch_no % 200 == 0:\n","\n","                    n_list=[21*random.randint(0,20)+14 for i in range(16)]\n","\n","                    input1 = []\n","                    target = []\n","\n","                    for n in n_list:\n","                        input1.append(test_data[n][0].numpy())\n","                        target.append(test_data[n+6][1].numpy())\n","\n","                    input1 = torch.tensor(input1)\n","                    target = torch.tensor(target)\n","                    input0 = input1.clone()\n","\n","                    # Validation\n","                    model.eval()\n","                    with torch.no_grad():\n","                        test_input_seq, test_input1_seq, test_target_seq = input0, input1, target\n","                        np_test_target_seq = test_target_seq.numpy()\n","                        test_input_seq, test_target_seq, test_input1_seq = test_input_seq.to(device, dtype=torch.float32), test_target_seq.to(device, dtype=torch.float32), test_input1_seq.to(device, dtype=torch.float32)\n","                        test_predicted_seq = loop_testing(test_input1_seq, 3, model)\n","                        np_test_predicted_seq = test_predicted_seq.cpu().numpy()\n","                        test_loss2 = criterion2(test_predicted_seq, test_target_seq)\n","                        mse_list.append(test_loss2)\n","                        test_loss3 = ssim(np_test_target_seq, np_test_predicted_seq, data_range=np_test_predicted_seq.max() - np_test_predicted_seq.min(), channel_axis=1)\n","                        ssim_list.append(test_loss3)\n","\n","                        print(\"Iter:{:5d}|Train loss: {:.4f}|Test loss MSE: {:.4f}|Test loss SSIM:{:.4f}\".format(batch_no, train_loss,test_loss2, test_loss3))\n","\n","    \"\"\"    os.makedirs('/content/trained_models/', exist_ok=True)\n","    model_path = os.path.join('/content/trained_models/', 'convlstm.pt')\n","    torch.save(model.state_dict(), model_path)\"\"\"\n","    if test:\n","        return model, mse_list, ssim_list\n","    else:\n","        return model\n"]},{"cell_type":"markdown","metadata":{"id":"2pgfyqeAwTOT"},"source":["#### data function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"79iq5kLwysgd"},"outputs":[],"source":["def count_fire(forest):\n","    count_list=[]\n","\n","    i, m, n = np.shape(forest)\n","\n","    for i1 in range(i):\n","        count = 0\n","        for m1 in range(m):\n","            for n1 in range(n):\n","                if forest[i1][m1][n1] == 1:\n","                    count += 1\n","        count_list.append(count)\n","\n","    return count_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PWnyfQE_clwJ"},"outputs":[],"source":["def loop_testing_msessimrpe_1to1(test_data, m):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    input1, target1 = test_data[m]\n","    _, target3 = test_data[m+3]\n","    _, target6 = test_data[m+6]\n","    _, target9 = test_data[m+9]\n","    _, target12 = test_data[m+12]\n","    input0 = input1.clone()\n","\n","    input1 = input1.to(device, dtype=torch.float32).unsqueeze(0)\n","    target1 = target1.to(device, dtype=torch.float32).unsqueeze(0)\n","    target3 = target3.to(device, dtype=torch.float32).unsqueeze(0)\n","    target6 = target6.to(device, dtype=torch.float32).unsqueeze(0)\n","    target9 = target9.to(device, dtype=torch.float32).unsqueeze(0)\n","    target12 = target12.to(device, dtype=torch.float32).unsqueeze(0)\n","\n","    mse_list = []\n","    ssim_list = []\n","    rpe_list = []\n","    pre_fire_count = []\n","    tar_fire_count = []\n","\n","    time_list=[]\n","\n","    mse = nn.MSELoss()\n","\n","    #loop=1\n","    old_input = input1\n","    start = time.time()\n","    input1 = convLSTM(old_input).detach()\n","    time_list.append(time.time()-start)\n","    input1 = torch.argmax(input1, dim=1)\n","\n","    np_input1 = input1.cpu().squeeze(0).numpy()\n","    np_target1 = target1.cpu().squeeze(0).numpy()\n","\n","    for i in range(3):\n","        test_loss2 = mse(input1[0][i], target1[0][i])\n","        mse_list.append(test_loss2)\n","\n","    for i in range(3):\n","        test_loss3 = ssim(np_target1[i], np_input1[i], data_range=np_input1[i].max() - np_input1[i].min(), channel_axis=0)\n","        ssim_list.append(test_loss3)\n","\n","    for i in range(3):\n","        test_loss4 = np.sum(np_target1[i] != np_input1[i])/(128*128)\n","        rpe_list.append(test_loss4)\n","\n","    pre_fire_count.append(count_fire(np_input1))\n","    tar_fire_count.append(count_fire(np_target1))\n","\n","    input1 = torch.stack((input1, input1), dim=2)\n","\n","    #loop=2\n","    old_input = input1\n","    start = time.time()\n","    input1 = convLSTM(old_input).detach()\n","    time_list.append(time.time()-start)\n","    input1 = torch.argmax(input1, dim=1)\n","    np_input1 = input1.cpu().squeeze(0).numpy()\n","    np_target3 = target3.cpu().squeeze(0).numpy()\n","\n","    for i in range(3):\n","        test_loss2 = mse(input1[0][i], target3[0][i])\n","        mse_list.append(test_loss2)\n","\n","    for i in range(3):\n","        test_loss3 = ssim(np_target3[i], np_input1[i], data_range=np_input1[i].max() - np_input1[i].min(), channel_axis=0)\n","        ssim_list.append(test_loss3)\n","\n","    for i in range(3):\n","        test_loss4 = np.sum(np_target3[i] != np_input1[i])/(128*128)\n","        rpe_list.append(test_loss4)\n","\n","    pre_fire_count.append(count_fire(np_input1))\n","    tar_fire_count.append(count_fire(np_target3))\n","\n","    input1 = torch.stack((input1, input1), dim=2)\n","\n","    #loop=3\n","    old_input = input1\n","    #print(input.shape)\n","    start = time.time()\n","    input1 = convLSTM(old_input).detach()\n","    time_list.append(time.time()-start)\n","    input1 = torch.argmax(input1, dim=1)\n","    np_input1 = input1.cpu().squeeze(0).numpy()\n","    np_target6 = target6.cpu().squeeze(0).numpy()\n","\n","    for i in range(3):\n","        test_loss2 = mse(input1[0][i], target6[0][i])\n","        mse_list.append(test_loss2)\n","\n","    for i in range(3):\n","        test_loss3 = ssim(np_target6[i], np_input1[i], data_range=np_input1[i].max() - np_input1[i].min(), channel_axis=0)\n","        ssim_list.append(test_loss3)\n","\n","    for i in range(3):\n","        test_loss4 = np.sum(np_target6[i] != np_input1[i])/(128*128)\n","        rpe_list.append(test_loss4)\n","\n","    pre_fire_count.append(count_fire(np_input1))\n","    tar_fire_count.append(count_fire(np_target6))\n","\n","    input1 = torch.stack((input1, input1), dim=2)\n","\n","    #loop=4\n","    old_input = input1\n","    start = time.time()\n","    input1 = convLSTM(old_input).detach()\n","    time_list.append(time.time()-start)\n","    input1 = torch.argmax(input1, dim=1)\n","    np_input1 = input1.cpu().squeeze(0).numpy()\n","    np_target9 = target9.cpu().squeeze(0).numpy()\n","\n","\n","    for i in range(3):\n","        test_loss2 = mse(input1[0][i], target9[0][i])\n","        mse_list.append(test_loss2)\n","\n","    for i in range(3):\n","        test_loss3 = ssim(np_target9[i], np_input1[i], data_range=np_input1[i].max() - np_input1[i].min(), channel_axis=0)\n","        ssim_list.append(test_loss3)\n","\n","    for i in range(3):\n","        test_loss4 = np.sum(np_target9[i] != np_input1[i])/(128*128)\n","        rpe_list.append(test_loss4)\n","\n","    pre_fire_count.append(count_fire(np_input1))\n","    tar_fire_count.append(count_fire(np_target9))\n","\n","    input1 = torch.stack((input1, input1), dim=2)\n","\n","    #loop=5\n","    old_input = input1\n","    #print(input.shape)\n","    start = time.time()\n","    input1 = convLSTM(old_input).detach()\n","    time_list.append(time.time()-start)\n","    input1 = torch.argmax(input1, dim=1)\n","    np_input1 = input1.cpu().squeeze(0).numpy()\n","    np_target12 = target12.cpu().squeeze(0).numpy()\n","\n","    for i in range(3):\n","        test_loss2 = mse(input1[0][i], target12[0][i])\n","        mse_list.append(test_loss2)\n","\n","    for i in range(3):\n","        test_loss3 = ssim(np_target12[i], np_input1[i], data_range=np_input1[i].max() - np_input1[i].min(), channel_axis=0)\n","        ssim_list.append(test_loss3)\n","\n","    for i in range(3):\n","        test_loss4 = np.sum(np_target12[i] != np_input1[i])/(128*128)\n","        rpe_list.append(test_loss4)\n","\n","    pre_fire_count.append(count_fire(np_input1))\n","    tar_fire_count.append(count_fire(np_target12))\n","\n","    input1 = torch.argmax(input1, dim=1)\n","\n","    for i in range(len(mse_list)):\n","        mse_list[i] = float(mse_list[i].cpu())\n","\n","    return input0, input1, np.array(mse_list), np.array(ssim_list), np.array(rpe_list), pre_fire_count, tar_fire_count, time_list\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O9C3n1dwD_9i"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"5dm6ctGzcLF-"},"source":["#### model speed test\n","\n","change the model path for testing on different models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Oa7KrZVjGr9"},"outputs":[],"source":["# Load the model from the .pt file\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","input_dim = 2\n","hidden_dim = 128\n","convLSTM = EncoderDecoderConvLSTM(input_dim, hidden_dim).to(device)\n","model_path = os.path.join(directory + 'Data/trained_models/', 'convlstm_ferguson_rand_ig_rand_wind_3t1p.pt') # change the model path for testing on different models\n","convLSTM.load_state_dict(torch.load(model_path))\n","\n","# Set the model to evaluation mode (if needed)\n","convLSTM.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"kThUz9VsebSo"},"outputs":[],"source":["import json\n","\n","sizes = [128, 256, 384, 512, 640, 768]\n","conv_time_dic = {}\n","\n","for size in sizes:\n","    print(f'Now we are at size {size}')\n","    conv_time_dic[f'{size}'] = []\n","    InfFireDataset = FireDataset(np.random.rand(100,26,size,size), seq_len=6)\n","\n","    for n in tqdm(range(10)):\n","        m = 21*n + 6\n","        _, _, _, _, _, _, _, time_list = loop_testing_msessimrpe_1to1(InfFireDataset, m)\n","        conv_time_dic[f'{size}'] = conv_time_dic[f'{size}'] + time_list\n","    # print('\\n','size =',size, 'Inference time=', np.mean(mean_time_list))\n","\n","print(conv_time_dic)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wUMRQQ9vsbm0"},"outputs":[],"source":["# Saving the dictionary to a file\n","# change the file path for testing on different models\n","with open(directory + 'Data/inference_speed_evaluation_data/fer_t4_conv_time_dic.json', 'w') as json_file:\n","    json.dump(conv_time_dic, json_file)\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["TMxAZF9_1ace","2pgfyqeAwTOT","5dm6ctGzcLF-"],"gpuType":"T4","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyMzr4JpVqgGZ4VhCB+f1PyD"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}