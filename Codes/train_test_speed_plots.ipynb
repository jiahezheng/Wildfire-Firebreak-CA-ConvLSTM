{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"j99ylO2g7kVj"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","directory = ''  # your directory\n","\n","import sys\n","import math\n","\n","import random\n","import copy\n","\n","import pandas as pd\n","import numpy as np\n","\n","from tqdm import tqdm\n","import time\n","\n","import matplotlib.pyplot as plt\n","from matplotlib import cm\n","from matplotlib import animation as animation\n","\n","from PIL import Image\n","import matplotlib as mpl\n","\n","from PIL import Image, ImageSequence\n","from skimage.transform import resize\n"]},{"cell_type":"markdown","metadata":{"id":"1Txfo09mYcoI"},"source":["# plot training part"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x26eoycL8LV0"},"outputs":[],"source":["VERBOSE = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d3AFMB9S7QZ-"},"outputs":[],"source":["bear_train_loss = [\n","    2.7688, 0.0620, 0.0484, 0.0334, 0.0280, 0.0179, 0.0174,\n","    0.0159, 0.0142, 0.0118, 0.0165, 0.0142, 0.0115, 0.0120,\n","    0.0088, 0.0134, 0.0067, 0.0108, 0.0083, 0.0111, 0.0119,\n","    0.0071, 0.0079, 0.0086, 0.0092, 0.0112, 0.0095, 0.0081,\n","    0.0101, 0.0084, 0.0076, 0.0089, 0.0086, 0.0119, 0.0086\n","]\n","\n","bear_mse = [\n","    0.9752, 0.0304, 0.0252, 0.0183, 0.0176, 0.0095, 0.0091,\n","    0.0069, 0.0057, 0.0086, 0.0062, 0.0047, 0.0070, 0.0054,\n","    0.0056, 0.0070, 0.0051, 0.0054, 0.0049, 0.0039, 0.0040,\n","    0.0044, 0.0067, 0.0067, 0.0066, 0.0065, 0.0057, 0.0054,\n","    0.0058, 0.0046, 0.0042, 0.0055, 0.0037, 0.0038, 0.0055\n","]\n","\n","bear_rpe = [\n","    46.8087, 1.1188, 1.0019, 0.7836, 0.7621, 0.4378, 0.4197,\n","    0.3221, 0.2560, 0.4101, 0.2911, 0.2240, 0.3320, 0.2559,\n","    0.2693, 0.3311, 0.2386, 0.2599, 0.2326, 0.1884, 0.1929,\n","    0.2087, 0.3196, 0.3225, 0.3175, 0.3106, 0.2650, 0.2551,\n","    0.2797, 0.2205, 0.2004, 0.2614, 0.1782, 0.1805, 0.2617\n","]\n","\n","bear_ssim = [\n","    float('nan'), 0.7719, 0.7634, 0.9055, 0.8688, 0.9138, 0.9159,\n","    0.9230, 0.9586, 0.9379, 0.9450, 0.9290, 0.9331, 0.9555,\n","    0.9403, 0.9255, 0.9495, 0.9358, 0.9405, 0.9477, 0.9603,\n","    0.9370, 0.9243, 0.9300, 0.9313, 0.9365, 0.9758, 0.9319,\n","    0.9382, 0.9488, 0.9626, 0.9520, 0.9563, 0.9643, 0.9309\n","]\n","\n","bear_rrmse = [\n","    0.2469, 0.3766, 0.3119, 0.2259, 0.1599, 0.1329, 0.1187,\n","    0.1174, 0.1053, 0.1155, 0.1044, 0.0977, 0.1099, 0.0959,\n","    0.0999, 0.1012, 0.0965, 0.0962, 0.0970, 0.0844, 0.0903,\n","    0.0862, 0.1100, 0.0984, 0.1056, 0.0976, 0.0981, 0.0950,\n","    0.1020, 0.0912, 0.0818, 0.0984, 0.0883, 0.0827, 0.0905\n","]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HnKI4ni13yZp"},"outputs":[],"source":["chimney_train_loss = [\n","    2.7806, 0.0577, 0.0421, 0.0324, 0.0286, 0.0246, 0.0188,\n","    0.0135, 0.0136, 0.0124, 0.0171, 0.0128, 0.0126, 0.0146,\n","    0.0068, 0.0100, 0.0078, 0.0098, 0.0082, 0.0076, 0.0073,\n","    0.0096, 0.0044, 0.0096, 0.0075, 0.0055, 0.0106, 0.0129,\n","    0.0109, 0.0128, 0.0126, 0.0080, 0.0058, 0.0062, 0.0129\n","]\n","\n","chimney_mse = [\n","    194.1037, 0.0296, 0.0211, 0.0190, 0.0103, 0.0085, 0.0067,\n","    0.0055, 0.0057, 0.0066, 0.0049, 0.0049, 0.0054, 0.0093,\n","    0.0047, 0.0054, 0.0047, 0.0034, 0.0038, 0.0058, 0.0046,\n","    0.0052, 0.0057, 0.0044, 0.0051, 0.0045, 0.0045, 0.0051,\n","    0.0034, 0.0043, 0.0039, 0.0067, 0.0030, 0.0067, 0.0037\n","]\n","\n","chimney_rpe = [\n","    48.0000, 1.0330, 0.7137, 0.8020, 0.4139, 0.3820, 0.3160,\n","    0.2613, 0.2719, 0.3162, 0.2345, 0.2346, 0.2583, 0.4445,\n","    0.2254, 0.2581, 0.2262, 0.1629, 0.1824, 0.2762, 0.2205,\n","    0.2497, 0.2585, 0.2110, 0.2458, 0.2158, 0.2155, 0.2466,\n","    0.1624, 0.2063, 0.1882, 0.3214, 0.1422, 0.3238, 0.1791\n","]\n","\n","chimney_ssim = [\n","    0.0019, 0.7154, 0.7744, 0.8288, 0.8944, 0.8926, 0.9059,\n","    0.9310, 0.9410, 0.9391, 0.9290, 0.9331, 0.9438, 0.8989,\n","    0.9450, 0.9363, 0.9357, 0.9581, 0.9507, 0.9267, 0.9407,\n","    0.9335, 0.9693, 0.9533, 0.9415, 0.9403, 0.9492, 0.9424,\n","    0.9578, 0.9453, 0.9507, 0.9412, 0.9604, 0.9219, 0.9481\n","]\n","\n","chimney_rrmse = [\n","    0.2496, 0.5421, 0.3314, 0.2134, 0.1578, 0.1447, 0.1213,\n","    0.1161, 0.1158, 0.1029, 0.1144, 0.0958, 0.1017, 0.1448,\n","    0.1026, 0.0946, 0.0981, 0.0937, 0.0999, 0.1111, 0.1040,\n","    0.1035, 0.1036, 0.1014, 0.1005, 0.0942, 0.0925, 0.1028,\n","    0.0787, 0.0927, 0.0874, 0.1193, 0.0749, 0.1157, 0.0921\n","]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oRBnBneR90AC"},"outputs":[],"source":["fer_train_loss = [\n","    2.8045, 0.0511, 0.0475, 0.0335, 0.0231, 0.0249, 0.0222,\n","    0.0296, 0.0196, 0.0141, 0.0140, 0.0095, 0.0138, 0.0143,\n","    0.0113, 0.0154, 0.0126, 0.0098, 0.0101, 0.0113, 0.0100,\n","    0.0137, 0.0073, 0.0061, 0.0089, 0.0069, 0.0146, 0.0097,\n","    0.0110, 0.0090, 0.0067, 0.0071, 0.0097, 0.0058, 0.0065\n","]\n","\n","fer_mse = [\n","    99.4054, 0.0367, 0.0298, 0.0199, 0.0144, 0.0108, 0.0077,\n","    0.0105, 0.0070, 0.0082, 0.0060, 0.0061, 0.0059, 0.0056,\n","    0.0038, 0.0045, 0.0060, 0.0058, 0.0083, 0.0062, 0.0062,\n","    0.0050, 0.0042, 0.0078, 0.0056, 0.0042, 0.0051, 0.0062,\n","    0.0048, 0.0038, 0.0049, 0.0045, 0.0047, 0.0042, 0.0073\n","]\n","\n","fer_rpe = [\n","    48.0000, 1.4877, 1.1944, 0.8367, 0.5799, 0.4900, 0.3436,\n","    0.4902, 0.3283, 0.3888, 0.2868, 0.2881, 0.2801, 0.2701,\n","    0.1835, 0.2163, 0.2892, 0.2803, 0.3985, 0.2965, 0.2970,\n","    0.2418, 0.2039, 0.3759, 0.2690, 0.2037, 0.2441, 0.2988,\n","    0.2281, 0.1820, 0.2336, 0.2155, 0.2249, 0.2021, 0.3524\n","]\n","\n","fer_ssim = [\n","    0.0018, 0.7118, 0.7406, 0.8215, 0.8671, 0.9071, 0.9225,\n","    0.9187, 0.9199, 0.9201, 0.9410, 0.9386, 0.9379, 0.9314,\n","    0.9609, 0.9498, 0.9385, 0.9461, 0.9121, 0.9329, 0.9434,\n","    0.9564, 0.9592, 0.9263, 0.9500, 0.9533, 0.9588, 0.9376,\n","    0.9548, 0.9620, 0.9485, 0.9534, 0.9538, 0.9524, 0.9388\n","]\n","\n","fer_rrmse = [\n","    0.2493, 0.3623, 0.3342, 0.2494, 0.1548, 0.1318, 0.1240,\n","    0.1338, 0.1078, 0.1262, 0.1016, 0.1023, 0.1011, 0.1068,\n","    0.0895, 0.0975, 0.1017, 0.1064, 0.1286, 0.1042, 0.0926,\n","    0.0943, 0.0849, 0.1101, 0.0932, 0.0844, 0.0926, 0.1001,\n","    0.0894, 0.0825, 0.0884, 0.0891, 0.0884, 0.0864, 0.1070\n","]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hNfT3lQV71Ar"},"outputs":[],"source":["iteration_labels = [i * 200 for i in range(len(fer_ssim))]\n","\n","# Creating the plot\n","plt.figure(figsize=(10, 6))\n","plt.plot(iteration_labels, bear_train_loss, label='Train MSE (Bear)', marker='o')\n","plt.plot(iteration_labels, chimney_train_loss, label='Train MSE (Chimney)', marker='o')\n","plt.plot(iteration_labels, fer_train_loss, label='Train MSE (Ferguson)', marker='o')\n","\n","plt.plot(iteration_labels, bear_mse, label='Validation MSE (Bear)', linestyle='--', marker='x')\n","plt.plot(iteration_labels, chimney_mse, label='Validation MSE (Chimney)', linestyle='--', marker='x')\n","plt.plot(iteration_labels, fer_mse, label='Validation MSE (Ferguson)', linestyle='--', marker='x')\n","\n","plt.xlabel('Iterations', fontsize=25)\n","plt.ylabel('MSE', fontsize=25)\n","plt.ylim(0,0.1)\n","#plt.title('Train and Validation MSE Loss per Iteration')\n","plt.legend(fontsize=25)\n","\n","# Set the size of tick labels and axis labels globally\n","plt.rcParams['xtick.labelsize'] = 18  # size of numbers on x-axis\n","plt.rcParams['ytick.labelsize'] = 18  # size of numbers on y-axis\n","plt.rcParams['axes.labelsize'] = 21   # size of x and y labels\n","plt.grid(True, linewidth=1.5)\n","\n","if VERBOSE:\n","    image_directory = directory + 'Plots/'\n","    plt.savefig(image_directory + 'train_val_loss_mse' + '.pdf', format='pdf',bbox_inches='tight')\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JpsG7-ecxRj3"},"outputs":[],"source":["iteration_labels = [i * 200 for i in range(len(fer_ssim))]\n","\n","# Creating the plot\n","plt.figure(figsize=(10, 6))\n","\n","plt.plot(iteration_labels, bear_ssim, label='SSIM (Bear)', marker='o')\n","plt.plot(iteration_labels, chimney_ssim, label='SSIM (Chimney)', marker='o')\n","plt.plot(iteration_labels, fer_ssim, label='SSIM (Ferguson)', marker='o')\n","\n","plt.xlabel('Iterations', fontsize=25)\n","plt.ylabel('SSIM', fontsize=25)\n","#plt.title('Train and Validation MSE Loss per Iteration')\n","plt.legend(fontsize=25)\n","# Set the size of tick labels and axis labels globally\n","plt.rcParams['xtick.labelsize'] = 18  # size of numbers on x-axis\n","plt.rcParams['ytick.labelsize'] = 18  # size of numbers on y-axis\n","plt.rcParams['axes.labelsize'] = 21   # size of x and y labels\n","plt.grid(True, linewidth=1.5)\n","\n","plt.ylim(0.7,1)\n","\n","\n","if VERBOSE:\n","    image_directory = directory + 'Plots/'\n","    plt.savefig(image_directory + 'val_loss_ssim' + '.pdf', format='pdf',bbox_inches='tight')\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2aZB3MMSxlpi"},"outputs":[],"source":["iteration_labels = [i * 200 for i in range(len(fer_ssim))]\n","\n","# Creating the plot\n","plt.figure(figsize=(10, 6))\n","\n","plt.plot(iteration_labels, bear_rpe, label='RPE (Bear)', marker='x')\n","plt.plot(iteration_labels, chimney_rpe, label='RPE (Chimney)', marker='x')\n","plt.plot(iteration_labels, fer_rpe, label='RPE (Ferguson)', marker='x')\n","\n","plt.xlabel('Iterations', fontsize=25)\n","plt.ylabel('RPE', fontsize=25)\n","#plt.title('Train and Validation MSE Loss per Iteration')\n","plt.legend(fontsize=25)\n","# Set the size of tick labels and axis labels globally\n","plt.rcParams['xtick.labelsize'] = 18  # size of numbers on x-axis\n","plt.rcParams['ytick.labelsize'] = 18  # size of numbers on y-axis\n","plt.rcParams['axes.labelsize'] = 21   # size of x and y labels\n","plt.grid(True, linewidth=1.5)\n","\n","\n","plt.ylim(0,0.5)\n","\n","if VERBOSE:\n","    image_directory = directory + 'Plots/'\n","    plt.savefig(image_directory + 'val_loss_rpe' + '.pdf', format='pdf',bbox_inches='tight')\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p7dt1uhwYHaT"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def plot_ssim(iteration_labels=None, data_series, labels, xlabel='', ylabel='', verbose=False, image_directory=''):\n","    \"\"\"\n","    Plot SSIM values with customized styling options and save the plot if verbose is True.\n","\n","    Args:\n","    iteration_labels (list): List of iteration labels for the x-axis.\n","    data_series (list of lists): List containing SSIM data series for each entity.\n","    labels (list): List of labels for each SSIM data series.\n","    xlabel (str): Label for the x-axis.\n","    ylabel (str): Label for the y-axis.\n","    verbose (bool): If True, save the plot to the specified image_directory.\n","    image_directory (str): image_directory path to save the plot file.\n","    \"\"\"\n","    if not iteration_labels:\n","        iteration_labels = [i for i in range(len(fer_ssim))]\n","\n","    plt.figure(figsize=(10, 6))\n","\n","    # Plot each series of data\n","    for series, label in zip(data_series, labels):\n","        plt.plot(iteration_labels, series, label=f'SSIM ({label})', marker='o')\n","\n","    # Set labels and title\n","    plt.xlabel(xlabel, fontsize=25)\n","    plt.ylabel(ylabel, fontsize=25)\n","\n","    # Legend, grid and styles\n","    plt.legend(fontsize=25)\n","    plt.grid(True, linewidth=1.5)\n","\n","    # Set the range of y-axis\n","    plt.ylim(0.7, 1)\n","\n","    # Customize the tick marks and labels\n","    plt.rcParams['xtick.labelsize'] = 18\n","    plt.rcParams['ytick.labelsize'] = 18\n","    plt.rcParams['axes.labelsize'] = 21\n","\n","    # Save the plot if verbose is true\n","    if verbose:\n","        if image_directory:\n","            filename = image_directory + f'val_loss_{ylabel}.pdf'\n","            plt.savefig(filename, format='pdf', bbox_inches='tight')\n","            print(f\"Saved plot to {filename}\")\n","        else:\n","            print(\"image_directory is not specified. Plot is not saved.\")\n","\n","    # Show the plot\n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E3NjZ-23Za_J"},"outputs":[],"source":["# Example usage:\n","it_labels = [i * 200 for i in range(len(fer_ssim))]  # fer_ssim needs to be defined\n","bear_ssim = []  # Define or load data\n","chimney_ssim = []  # Define or load data\n","fer_ssim = []  # Define or load data\n","\n","plot_ssim(\n","    iteration_labels=it_labels,\n","    data_series=[bear_ssim, chimney_ssim, fer_ssim],\n","    labels=['Bear', 'Chimney', 'Ferguson'],\n","    xlabel='Iterations',\n","    ylabel='SSIM',\n","    verbose=VERBOSE,\n","    image_directory= directory + 'Plots/'\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"OGd4MTksOVXO"},"source":["# plot test part"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wCBIT7vcNRuS"},"outputs":[],"source":["mse_2_p_list_chimney = np.load(directory + 'Data/test_metric_data/Chimney_data/mse_2_p_array.npy')\n","ssim_2_p_list_chimney = np.load(directory + 'Data/test_metric_data/Chimney_data/ssim_2_p_array.npy')\n","rpe_2_p_list_chimney = np.load(directory + 'Data/test_metric_data/Chimney_data/rpe_2_p_array.npy')\n","\n","mse_3_t_list_chimney = np.load(directory + 'Data/test_metric_data/Chimney_data/mse_3_t_array.npy')\n","rpe_3_t_list_chimney = np.load(directory + 'Data/test_metric_data/Chimney_data/rpe_3_t_array.npy')\n","ssim_3_t_list_chimney = np.load(directory + 'Data/test_metric_data/Chimney_data/ssim_3_t_array.npy')\n","\n","mse_4_pt_list_chimney = np.load(directory + 'Data/test_metric_data/Chimney_data/mse_4_pt_array.npy')\n","rpe_4_pt_list_chimney = np.load(directory + 'Data/test_metric_data/Chimney_data/rpe_4_pt_array.npy')\n","ssim_4_pt_list_chimney = np.load(directory + 'Data/test_metric_data/Chimney_data/ssim_4_pt_array.npy')\n","\n","mse_no_pt_list_chimney = np.load(directory + 'Data/test_metric_data/Chimney_data/mse_no_pt_array.npy')\n","rpe_no_pt_list_chimney = np.load(directory + 'Data/test_metric_data/Chimney_data/rpe_no_pt_array.npy')\n","ssim_no_pt_list_chimney = np.load(directory + 'Data/test_metric_data/Chimney_data/ssim_no_pt_array.npy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fn_yU3dONRuS"},"outputs":[],"source":["mse_2_p_list_ferguson = np.load(directory + 'Data/test_metric_data/Ferguson_data/mse_2_p_array.npy')\n","ssim_2_p_list_ferguson = np.load(directory + 'Data/test_metric_data/Ferguson_data/ssim_2_p_array.npy')\n","rpe_2_p_list_ferguson = np.load(directory + 'Data/test_metric_data/Ferguson_data/rpe_2_p_array.npy')\n","\n","mse_3_t_list_ferguson = np.load(directory + 'Data/test_metric_data/Ferguson_data/mse_3_t_array.npy')\n","rpe_3_t_list_ferguson = np.load(directory + 'Data/test_metric_data/Ferguson_data/rpe_3_t_array.npy')\n","ssim_3_t_list_ferguson = np.load(directory + 'Data/test_metric_data/Ferguson_data/ssim_3_t_array.npy')\n","\n","mse_4_pt_list_ferguson = np.load(directory + 'Data/test_metric_data/Ferguson_data/mse_4_pt_array.npy')\n","rpe_4_pt_list_ferguson = np.load(directory + 'Data/test_metric_data/Ferguson_data/rpe_4_pt_array.npy')\n","ssim_4_pt_list_ferguson = np.load(directory + 'Data/test_metric_data/Ferguson_data/ssim_4_pt_array.npy')\n","\n","mse_no_pt_list_ferguson = np.load(directory + 'Data/test_metric_data/Ferguson_data/mse_no_pt_array.npy')\n","rpe_no_pt_list_ferguson = np.load(directory + 'Data/test_metric_data/Ferguson_data/rpe_no_pt_array.npy')\n","ssim_no_pt_list_ferguson = np.load(directory + 'Data/test_metric_data/Ferguson_data/ssim_no_pt_array.npy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DHG0zYQoNRuS"},"outputs":[],"source":["mse_2_p_list_bear = np.load(directory + 'Data/test_metric_data/Bear_data/mse_2_p_array.npy')\n","ssim_2_p_list_bear = np.load(directory + 'Data/test_metric_data/Bear_data/ssim_2_p_array.npy')\n","rpe_2_p_list_bear = np.load(directory + 'Data/test_metric_data/Bear_data/rpe_2_p_array.npy')\n","\n","mse_3_t_list_bear = np.load(directory + 'Data/test_metric_data/Bear_data/mse_3_t_array.npy')\n","rpe_3_t_list_bear = np.load(directory + 'Data/test_metric_data/Bear_data/rpe_3_t_array.npy')\n","ssim_3_t_list_bear = np.load(directory + 'Data/test_metric_data/Bear_data/ssim_3_t_array.npy')\n","\n","mse_4_pt_list_bear = np.load(directory + 'Data/test_metric_data/Bear_data/mse_4_pt_array.npy')\n","rpe_4_pt_list_bear = np.load(directory + 'Data/test_metric_data/Bear_data/rpe_4_pt_array.npy')\n","ssim_4_pt_list_bear = np.load(directory + 'Data/test_metric_data/Bear_data/ssim_4_pt_array.npy')\n","\n","mse_no_pt_list_bear = np.load(directory + 'Data/test_metric_data/Bear_data/mse_no_pt_array.npy')\n","rpe_no_pt_list_bear = np.load(directory + 'Data/test_metric_data/Bear_data/rpe_no_pt_array.npy')\n","ssim_no_pt_list_bear = np.load(directory + 'Data/test_metric_data/Bear_data/ssim_no_pt_array.npy')"]},{"cell_type":"code","source":["import numpy as np\n","\n","def filter_outliers(data, threshold=1.5):\n","    \"\"\"Filters outliers using the interquartile range (IQR) method, ignoring NaN values.\"\"\"\n","    data = data[~np.isnan(data)]  # Remove NaN values before filtering\n","    if data.size == 0:\n","        return np.array([])  # Return an empty array if all values are NaN\n","\n","    q25, q75 = np.percentile(data, 25), np.percentile(data, 75)\n","    iqr = q75 - q25\n","    cut_off = iqr * threshold\n","    lower, upper = q25 - cut_off, q75 + cut_off\n","    filtered_data = data[(data >= lower) & (data <= upper)]\n","    return filtered_data\n","\n","def calculate_filtered_mean(data):\n","    \"\"\"Calculates mean after filtering outliers, ignoring NaN values.\"\"\"\n","    filtered_data = filter_outliers(data)\n","    if filtered_data.size == 0:  # If no data remains after filtering\n","        return np.nan\n","    return np.nanmean(filtered_data)  # Use np.nanmean to ignore NaN values\n","\n","# Forests and configurations\n","forests = ['Chimney', 'Ferguson', 'Bear']\n","configurations = ['2_p', '3_t', '4_pt', 'no_pt']\n","metrics = ['mse', 'rpe', 'ssim']\n","\n","# Initialize a dictionary to store means\n","forest_config_means = {forest: {config: {metric: None for metric in metrics} for config in configurations} for forest in forests}\n","\n","# Process data for each forest, configuration, and metric\n","for forest in forests:\n","    for config in configurations:\n","        for metric in metrics:\n","            # Construct the file path and load the data\n","            file_path = directory + 'Data/test_metric_data/{forest}_data/{metric}_{config}_array.npy\"\n","            try:\n","                data = np.load(file_path)\n","                forest_config_means[forest][config][metric] = calculate_filtered_mean(data)\n","            except Exception as e:\n","                forest_config_means[forest][config][metric] = f\"Error: {e}\"\n","\n","# Convert results to DataFrame\n","import pandas as pd\n","results_df = pd.json_normalize(forest_config_means, sep='_').transpose()\n","results_df.columns = ['Filtered Mean']\n","results_df.reset_index(inplace=True)\n","results_df.rename(columns={\"index\": \"Forest_Config_Metric\"}, inplace=True)\n","\n","# Display the DataFrame\n","print(\"Filtered Means for Each Forest, Configuration, and Metric:\")\n","print(results_df)"],"metadata":{"id":"aPDTcR7lPkDm"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3fD6PdRHNRuS"},"outputs":[],"source":["# rpe_max = max([\n","#     max(array.max() for array in rpe_4_pt_list[0][:]),\n","#     max(array.max() for array in rpe_no_pt_list[0][:]),\n","#     max(array.max() for array in rpe_3_t_list[0][:]),\n","#     max(array.max() for array in rpe_2_p_list[0][:])\n","# ])*1.1\n","\n","# ssim_min = min([\n","#     min(array.min() for array in ssim_4_pt_list[0][:]),\n","#     min(array.min() for array in ssim_no_pt_list[0][:]),\n","#     min(array.min() for array in ssim_3_t_list[0][:]),\n","#     min(array.min() for array in ssim_2_p_list[0][:])\n","# ])\n"]},{"cell_type":"markdown","metadata":{"id":"9TuscWIENRuS"},"source":["mse"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eD_tTnF1hE22"},"outputs":[],"source":["mse_min = 0\n","\n","mse_max_chimney = max([\n","    max(array.max() for array in mse_4_pt_list_chimney[0][:]),\n","    max(array.max() for array in mse_no_pt_list_chimney[0][:]),\n","    max(array.max() for array in mse_3_t_list_chimney[0][:]),\n","    max(array.max() for array in mse_2_p_list_chimney[0][:])\n","])*1.1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"el-y_eCloqkA"},"outputs":[],"source":["VERBOSE = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5JHquEdprTy2"},"outputs":[],"source":["def filter_outliers(data, threshold=1.5):\n","    \"\"\"Filters outliers using interquartile range method.\"\"\"\n","    q25, q75 = np.percentile(data, 25), np.percentile(data, 75)\n","    iqr = q75 - q25\n","    cut_off = iqr * threshold\n","    lower, upper = q25 - cut_off, q75 + cut_off\n","    return data[(data >= lower) & (data <= upper)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"twyskdu5l_ux"},"outputs":[],"source":["mse_3_t_arr = np.array(mse_3_t_list_chimney)\n","y_value =mse_3_t_list_chimney*1.0\n","\n","# Filtering out outliers for each column\n","filtered_data = []\n","filtered_data.append([filter_outliers((np.array(mse_4_pt_list_chimney)*1.0)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers((np.array(mse_3_t_list_chimney)*1.0)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers((np.array(mse_2_p_list_chimney)*1.0)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers((np.array(mse_no_pt_list_chimney)*1.0)[:, idx]) for idx in range(y_value.shape[1])])\n","\n","label_list = ['3T1P', '3T', '2P', 'No bar']\n","# Calculate mean and standard deviation for each column\n","means_list = []\n","stds_list = []\n","for i in range(4):\n","    means=[]\n","    stds=[]\n","    for fd in filtered_data[i]:\n","        means.append(np.mean(fd))\n","        stds.append(np.std(fd))\n","\n","    means_list.append(means)\n","    stds_list.append(stds)\n","means_list = np.array(means_list)\n","stds_list = np.array(stds_list)\n","# means = np.mean(np.array(y_value), axis=0)\n","# std_devs = np.array(y_value).std(axis=0)\n","\n","x_values = range(1,16)\n","upper_bounds = means_list + stds_list\n","lower_bounds = means_list - stds_list\n","\n","\n","# Scatter plot for individual data points\n","plt.figure(figsize=(10, 6))\n","\n","plt.rcParams.update({'font.size': 16})\n","\n","# Dummy scatter plot for legend\n","plt.scatter([], [], color='red', s=10, alpha=0.5)\n","\n","for i in range(4):\n","    for idx, (x_val, column_data) in enumerate(zip(x_values, filtered_data[i])):\n","        plt.scatter([x_val]*len(column_data), column_data, s=10, alpha=0.5)\n","\n","    plt.plot(x_values, means_list[i], 'o-', label='Mean of ' + label_list[i])\n","    plt.fill_between(x_values, lower_bounds[i], upper_bounds[i], alpha=0.2, label='Std of ' + label_list[i])\n","\n","plt.xticks(x_values)\n","plt.xlabel('Time step', fontsize=25)\n","# plt.ylabel('Chimney MSE', fontsize=25)\n","plt.ylim([0, 0.03])\n","plt.grid(True)\n","\n","# # Set the legend outside the plot on the right side\n","# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=25)\n","\n","plt.tight_layout()  # Adjust layout to make room for the legend\n","\n","if VERBOSE:\n","    plt.savefig(directory + 'Plots/Chimney_MSE.pdf', format='pdf', bbox_inches='tight')\n","    print(\"Plot saved successfully.\")\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p_E1FProqtie"},"outputs":[],"source":["mse_min = 0\n","\n","mse_max_bear = max([\n","    max(array.max() for array in mse_4_pt_list_bear[0][:]),\n","    max(array.max() for array in mse_no_pt_list_bear[0][:]),\n","    max(array.max() for array in mse_3_t_list_bear[0][:]),\n","    max(array.max() for array in mse_2_p_list_bear[0][:])\n","])*1.1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EiBB52qLp-bM"},"outputs":[],"source":["mse_3_t_arr = np.array(mse_3_t_list_bear)  # Changed from 'chimney' to 'bear'\n","y_value = mse_3_t_list_bear * 1.0  # Changed from 'chimney' to 'bear'\n","\n","# Filtering out outliers for each column\n","filtered_data = []\n","filtered_data.append([filter_outliers(np.array(mse_4_pt_list_bear)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(mse_3_t_list_bear)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(mse_2_p_list_bear)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(mse_no_pt_list_bear)[:, idx]) for idx in range(y_value.shape[1])])\n","\n","label_list = ['3T1P', '3T', '2P', 'No bar']\n","means_list = []\n","stds_list = []\n","for i in range(4):\n","    means = []\n","    stds = []\n","    for fd in filtered_data[i]:\n","        means.append(np.mean(fd))\n","        stds.append(np.std(fd))\n","    means_list.append(means)\n","    stds_list.append(stds)\n","\n","means_list = np.array(means_list)\n","stds_list = np.array(stds_list)\n","\n","x_values = range(1, 16)\n","upper_bounds = means_list + stds_list\n","lower_bounds = means_list - stds_list\n","\n","# Scatter plot for individual data points\n","plt.figure(figsize=(10, 6))\n","plt.rcParams.update({'font.size': 16})\n","plt.scatter([], [], color='red', s=10, alpha=0.5)\n","\n","for i in range(4):\n","    for idx, (x_val, column_data) in enumerate(zip(x_values, filtered_data[i])):\n","        plt.scatter([x_val] * len(column_data), column_data, s=10, alpha=0.5)\n","\n","    plt.plot(x_values, means_list[i], 'o-', label='Mean of ' + label_list[i])\n","    plt.fill_between(x_values, lower_bounds[i], upper_bounds[i], alpha=0.2, label='Std of ' + label_list[i])\n","\n","plt.xticks(x_values)\n","plt.xlabel('Time step', fontsize=25)\n","# plt.ylabel('Bear MSE', fontsize=25)  # Changed label from 'Chimney' to 'Bear'\n","plt.ylim([0, 0.03])\n","plt.grid(True)\n","# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=25)\n","plt.tight_layout()  # Adjust layout to make room for the legend\n","\n","if VERBOSE:\n","    plt.savefig(directory + 'Plots/Bear_MSE.pdf', format='pdf', bbox_inches='tight')\n","    print(\"Plot saved successfully.\")\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fp9xtkfKqogi"},"outputs":[],"source":["mse_min = 0\n","\n","mse_max_ferguson = max([\n","    max(array.max() for array in mse_4_pt_list_ferguson[0][:]),\n","    max(array.max() for array in mse_no_pt_list_ferguson[0][:]),\n","    max(array.max() for array in mse_3_t_list_ferguson[0][:]),\n","    max(array.max() for array in mse_2_p_list_ferguson[0][:])\n","])*1.1\n","\n","\n","mse_3_t_arr = np.array(mse_3_t_list_ferguson)  # Changed from 'bear' to 'ferguson'\n","y_value = mse_3_t_list_ferguson * 1.0  # Changed from 'bear' to 'ferguson'\n","\n","# Filtering out outliers for each column\n","filtered_data = []\n","filtered_data.append([filter_outliers(np.array(mse_4_pt_list_ferguson)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(mse_3_t_list_ferguson)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(mse_2_p_list_ferguson)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(mse_no_pt_list_ferguson)[:, idx]) for idx in range(y_value.shape[1])])\n","\n","label_list = ['3T1P', '3T', '2P', 'No bar']\n","means_list = []\n","stds_list = []\n","for i in range(4):\n","    means = []\n","    stds = []\n","    for fd in filtered_data[i]:\n","        means.append(np.mean(fd))\n","        stds.append(np.std(fd))\n","    means_list.append(means)\n","    stds_list.append(stds)\n","\n","means_list = np.array(means_list)\n","stds_list = np.array(stds_list)\n","\n","x_values = range(1, 16)\n","upper_bounds = means_list + stds_list\n","lower_bounds = means_list - stds_list\n","\n","# Scatter plot for individual data points\n","plt.figure(figsize=(10, 6))\n","plt.rcParams.update({'font.size': 16})\n","plt.scatter([], [], color='red', s=10, alpha=0.5)\n","\n","for i in range(4):\n","    for idx, (x_val, column_data) in enumerate(zip(x_values, filtered_data[i])):\n","        plt.scatter([x_val] * len(column_data), column_data, s=10, alpha=0.5)\n","\n","    plt.plot(x_values, means_list[i], 'o-', label='Mean of ' + label_list[i])\n","    plt.fill_between(x_values, lower_bounds[i], upper_bounds[i], alpha=0.2, label='Std of ' + label_list[i])\n","\n","plt.xticks(x_values)\n","plt.xlabel('Time step', fontsize=25)\n","# plt.ylabel('Ferguson MSE', fontsize=25)  # Changed label from 'Bear' to 'Ferguson'\n","plt.ylim([0, 0.03])\n","plt.grid(True)\n","# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=25)\n","plt.tight_layout()  # Adjust layout to make room for the legend\n","\n","if VERBOSE:\n","    plt.savefig(directory + 'Plots/Ferguson_MSE.pdf', format='pdf', bbox_inches='tight')\n","    print(\"Plot saved successfully.\")\n","\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"tBeBXwYbruif"},"source":["rpe"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t0JqzN40rvls"},"outputs":[],"source":["rpe_min = 0\n","\n","rpe_max_ferguson = max([\n","    max(array.max() for array in rpe_4_pt_list_ferguson[0][:]),\n","    max(array.max() for array in rpe_no_pt_list_ferguson[0][:]),\n","    max(array.max() for array in rpe_3_t_list_ferguson[0][:]),\n","    max(array.max() for array in rpe_2_p_list_ferguson[0][:])\n","])*1.1\n","\n","rpe_3_t_arr = np.array(rpe_3_t_list_ferguson)  # Updated variable name\n","y_value = rpe_3_t_list_ferguson * 1.0  # Updated variable name\n","\n","# Filtering out outliers for each column\n","filtered_data = []\n","filtered_data.append([filter_outliers(np.array(rpe_4_pt_list_ferguson)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(rpe_3_t_list_ferguson)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(rpe_2_p_list_ferguson)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(rpe_no_pt_list_ferguson)[:, idx]) for idx in range(y_value.shape[1])])\n","\n","label_list = ['3T1P', '3T', '2P', 'No bar']\n","means_list = []\n","stds_list = []\n","for i in range(4):\n","    means = []\n","    stds = []\n","    for fd in filtered_data[i]:\n","        means.append(np.mean(fd))\n","        stds.append(np.std(fd))\n","    means_list.append(means)\n","    stds_list.append(stds)\n","\n","means_list = np.array(means_list)\n","stds_list = np.array(stds_list)\n","\n","x_values = range(1, 16)\n","upper_bounds = means_list + stds_list\n","lower_bounds = means_list - stds_list\n","\n","# Scatter plot for individual data points\n","plt.figure(figsize=(10, 6))\n","plt.rcParams.update({'font.size': 16})\n","plt.scatter([], [], color='red', s=10, alpha=0.5)\n","\n","for i in range(4):\n","    for idx, (x_val, column_data) in enumerate(zip(x_values, filtered_data[i])):\n","        plt.scatter([x_val] * len(column_data), column_data, s=10, alpha=0.5)\n","\n","    plt.plot(x_values, means_list[i], 'o-', label='Mean of ' + label_list[i])\n","    plt.fill_between(x_values, lower_bounds[i], upper_bounds[i], alpha=0.2, label='Std of ' + label_list[i])\n","\n","plt.xticks(x_values)\n","plt.xlabel('Time step', fontsize=25)\n","# plt.ylabel('Ferguson RPE', fontsize=25)  # Updated label\n","plt.ylim([0, 0.02])\n","plt.grid(True)\n","# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=25)\n","plt.tight_layout()  # Adjust layout to make room for the legend\n","\n","if VERBOSE:\n","    plt.savefig(directory + 'Plots/Ferguson_RPE.pdf', format='pdf', bbox_inches='tight')\n","    print(\"Plot saved successfully.\")\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5JfiNYXtrvjd"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def filter_outliers(data, threshold=1.5):\n","    \"\"\"Filters outliers using interquartile range method.\"\"\"\n","    q25, q75 = np.percentile(data, 25), np.percentile(data, 75)\n","    iqr = q75 - q25\n","    cut_off = iqr * threshold\n","    lower, upper = q25 - cut_off, q75 + cut_off\n","    return data[(data >= lower) & (data <= upper)]\n","\n","rpe_min = 0\n","\n","rpe_max_bear = max([\n","    max(array.max() for array in rpe_4_pt_list_bear[0][:]),\n","    max(array.max() for array in rpe_no_pt_list_bear[0][:]),\n","    max(array.max() for array in rpe_3_t_list_bear[0][:]),\n","    max(array.max() for array in rpe_2_p_list_bear[0][:])\n","])*1.1\n","\n","rpe_3_t_arr = np.array(rpe_3_t_list_bear)  # Updated variable name\n","y_value = rpe_3_t_list_bear * 1.0  # Updated variable name\n","\n","# Filtering out outliers for each column\n","filtered_data = []\n","filtered_data.append([filter_outliers(np.array(rpe_4_pt_list_bear)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(rpe_3_t_list_bear)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(rpe_2_p_list_bear)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(rpe_no_pt_list_bear)[:, idx]) for idx in range(y_value.shape[1])])\n","\n","label_list = ['3T1P', '3T', '2P', 'No bar']\n","means_list = []\n","stds_list = []\n","for i in range(4):\n","    means = []\n","    stds = []\n","    for fd in filtered_data[i]:\n","        means.append(np.mean(fd))\n","        stds.append(np.std(fd))\n","    means_list.append(means)\n","    stds_list.append(stds)\n","\n","means_list = np.array(means_list)\n","stds_list = np.array(stds_list)\n","\n","x_values = range(1, 16)\n","upper_bounds = means_list + stds_list\n","lower_bounds = means_list - stds_list\n","\n","# Scatter plot for individual data points\n","plt.figure(figsize=(10, 6))\n","plt.rcParams.update({'font.size': 16})\n","plt.scatter([], [], color='red', s=10, alpha=0.5)\n","\n","for i in range(4):\n","    for idx, (x_val, column_data) in enumerate(zip(x_values, filtered_data[i])):\n","        plt.scatter([x_val] * len(column_data), column_data, s=10, alpha=0.5)\n","\n","    plt.plot(x_values, means_list[i], 'o-', label='Mean of ' + label_list[i])\n","    plt.fill_between(x_values, lower_bounds[i], upper_bounds[i], alpha=0.2, label='Std of ' + label_list[i])\n","\n","plt.xticks(x_values)\n","plt.xlabel('Time step', fontsize=25)\n","# plt.ylabel('Bear RPE', fontsize=25)\n","plt.ylim([0, 0.02])\n","plt.grid(True)\n","# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=25)\n","plt.tight_layout()  # Adjust layout to make room for the legend\n","\n","if VERBOSE:\n","    plt.savefig(directory + 'Plots/Bear_RPE.pdf', format='pdf', bbox_inches='tight')\n","    print(\"Plot saved successfully.\")\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AqTQkwQ4rvhR"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def filter_outliers(data, threshold=1.5):\n","    \"\"\"Filters outliers using interquartile range method.\"\"\"\n","    q25, q75 = np.percentile(data, 25), np.percentile(data, 75)\n","    iqr = q75 - q25\n","    cut_off = iqr * threshold\n","    lower, upper = q25 - cut_off, q75 + cut_off\n","    return data[(data >= lower) & (data <= upper)]\n","\n","rpe_min = 0\n","\n","rpe_max_chimney = max([\n","    max(array.max() for array in rpe_4_pt_list_chimney[0][:]),\n","    max(array.max() for array in rpe_no_pt_list_chimney[0][:]),\n","    max(array.max() for array in rpe_3_t_list_chimney[0][:]),\n","    max(array.max() for array in rpe_2_p_list_chimney[0][:])\n","])*1.1\n","\n","rpe_3_t_arr = np.array(rpe_3_t_list_chimney)  # Updated variable name\n","y_value = rpe_3_t_list_chimney * 1.0  # Updated variable name\n","\n","# Filtering out outliers for each column\n","filtered_data = []\n","filtered_data.append([filter_outliers(np.array(rpe_4_pt_list_chimney)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(rpe_3_t_list_chimney)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(rpe_2_p_list_chimney)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(rpe_no_pt_list_chimney)[:, idx]) for idx in range(y_value.shape[1])])\n","\n","label_list = ['3T1P', '3T', '2P', 'No bar']\n","means_list = []\n","stds_list = []\n","for i in range(4):\n","    means = []\n","    stds = []\n","    for fd in filtered_data[i]:\n","        means.append(np.mean(fd))\n","        stds.append(np.std(fd))\n","    means_list.append(means)\n","    stds_list.append(stds)\n","\n","means_list = np.array(means_list)\n","stds_list = np.array(stds_list)\n","\n","x_values = range(1, 16)\n","upper_bounds = means_list + stds_list\n","lower_bounds = means_list - stds_list\n","\n","# Scatter plot for individual data points\n","plt.figure(figsize=(10, 6))\n","plt.rcParams.update({'font.size': 16})\n","plt.scatter([], [], color='red', s=10, alpha=0.5)\n","\n","for i in range(4):\n","    for idx, (x_val, column_data) in enumerate(zip(x_values, filtered_data[i])):\n","        plt.scatter([x_val] * len(column_data), column_data, s=10, alpha=0.5)\n","\n","    plt.plot(x_values, means_list[i], 'o-', label='Mean of ' + label_list[i])\n","    plt.fill_between(x_values, lower_bounds[i], upper_bounds[i], alpha=0.2, label='Std of ' + label_list[i])\n","\n","plt.xticks(x_values)\n","plt.xlabel('Time step', fontsize=25)\n","# plt.ylabel('Chimney RPE', fontsize=25)\n","plt.ylim([0, 0.02])\n","plt.grid(True)\n","# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=25)\n","plt.tight_layout()  # Adjust layout to make room for the legend\n","\n","if VERBOSE:\n","    plt.savefig(directory + 'Plots/Chimney_RPE.pdf', format='pdf', bbox_inches='tight')\n","    print(\"Plot saved successfully.\")\n","\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"TbGn_sootECK"},"source":["ssim"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HU12e_9M1buV"},"outputs":[],"source":["VERBOSE = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JI4vHrq5srGm"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def filter_outliers(data, threshold=1.5):\n","    \"\"\"Filters outliers using interquartile range method.\"\"\"\n","    q25, q75 = np.percentile(data, 25), np.percentile(data, 75)\n","    iqr = q75 - q25\n","    cut_off = iqr * threshold\n","    lower, upper = q25 - cut_off, q75 + cut_off\n","    return data[(data >= lower) & (data <= upper)]\n","\n","ssim_max = 1\n","\n","ssim_min_bear = min([\n","    min(array.min() for array in ssim_4_pt_list_bear[0][:]),\n","    min(array.min() for array in ssim_no_pt_list_bear[0][:]),\n","    min(array.min() for array in ssim_3_t_list_bear[0][:]),\n","    min(array.min() for array in ssim_2_p_list_bear[0][:])\n","])\n","\n","ssim_3_t_arr = np.array(ssim_3_t_list_bear)\n","y_value = ssim_3_t_list_bear * 1.0\n","\n","# Filtering out outliers for each column\n","filtered_data = []\n","filtered_data.append([filter_outliers(np.array(ssim_4_pt_list_bear)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(ssim_3_t_list_bear)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(ssim_2_p_list_bear)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(ssim_no_pt_list_bear)[:, idx]) for idx in range(y_value.shape[1])])\n","\n","label_list = ['3T1P', '3T', '2P', 'None']\n","means_list = []\n","stds_list = []\n","for i in range(4):\n","    means = []\n","    stds = []\n","    for fd in filtered_data[i]:\n","        means.append(np.mean(fd))\n","        stds.append(np.std(fd))\n","    means_list.append(means)\n","    stds_list.append(stds)\n","\n","means_list = np.array(means_list)\n","stds_list = np.array(stds_list)\n","\n","x_values = range(1, 16)\n","upper_bounds = means_list + stds_list\n","lower_bounds = means_list - stds_list\n","\n","# Scatter plot for individual data points\n","plt.figure(figsize=(12, 6))\n","plt.rcParams.update({'font.size': 16})\n","plt.scatter([], [], color='red', s=10, alpha=0.5)\n","\n","for i in range(4):\n","    for idx, (x_val, column_data) in enumerate(zip(x_values, filtered_data[i])):\n","        plt.scatter([x_val] * len(column_data), column_data, s=10, alpha=0.5)\n","\n","    plt.plot(x_values, means_list[i], 'o-', label='Mean of ' + label_list[i])\n","    plt.fill_between(x_values, lower_bounds[i], upper_bounds[i], alpha=0.2, label='Std of ' + label_list[i])\n","\n","plt.xticks(x_values)\n","plt.xlabel('Time step', fontsize=25)\n","# plt.ylabel('Bear SSIM', fontsize=25)\n","plt.ylim([0.96, ssim_max])\n","plt.grid(True)\n","plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=25, ncol = 8 )\n","plt.tight_layout()\n","\n","if VERBOSE:\n","    plt.savefig(directory + 'Plots/legend.pdf', format='pdf', bbox_inches='tight')\n","    print(\"Plot saved successfully.\")\n","\n","plt.show()\n"]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def filter_outliers(data, threshold=1.5):\n","    \"\"\"Filters outliers using interquartile range method.\"\"\"\n","    q25, q75 = np.percentile(data, 25), np.percentile(data, 75)\n","    iqr = q75 - q25\n","    cut_off = iqr * threshold\n","    lower, upper = q25 - cut_off, q75 + cut_off\n","    return data[(data >= lower) & (data <= upper)]\n","\n","ssim_max = 1\n","\n","ssim_min_bear = min([\n","    min(array.min() for array in ssim_4_pt_list_bear[0][:]),\n","    min(array.min() for array in ssim_no_pt_list_bear[0][:]),\n","    min(array.min() for array in ssim_3_t_list_bear[0][:]),\n","    min(array.min() for array in ssim_2_p_list_bear[0][:])\n","])\n","\n","ssim_3_t_arr = np.array(ssim_3_t_list_bear)\n","y_value = ssim_3_t_list_bear * 1.0\n","\n","# Filtering out outliers for each column\n","filtered_data = []\n","filtered_data.append([filter_outliers(np.array(ssim_4_pt_list_bear)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(ssim_3_t_list_bear)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(ssim_2_p_list_bear)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(ssim_no_pt_list_bear)[:, idx]) for idx in range(y_value.shape[1])])\n","\n","label_list = ['3T1P', '3T', '2P', 'No bar']\n","means_list = []\n","stds_list = []\n","for i in range(4):\n","    means = []\n","    stds = []\n","    for fd in filtered_data[i]:\n","        means.append(np.mean(fd))\n","        stds.append(np.std(fd))\n","    means_list.append(means)\n","    stds_list.append(stds)\n","\n","means_list = np.array(means_list)\n","stds_list = np.array(stds_list)\n","\n","x_values = range(1, 16)\n","upper_bounds = means_list + stds_list\n","lower_bounds = means_list - stds_list\n","\n","# Scatter plot for individual data points\n","plt.figure(figsize=(10, 6))\n","plt.rcParams.update({'font.size': 16})\n","plt.scatter([], [], color='red', s=10, alpha=0.5)\n","\n","for i in range(4):\n","    for idx, (x_val, column_data) in enumerate(zip(x_values, filtered_data[i])):\n","        plt.scatter([x_val] * len(column_data), column_data, s=10, alpha=0.5)\n","\n","    plt.plot(x_values, means_list[i], 'o-', label='Mean of ' + label_list[i])\n","    plt.fill_between(x_values, lower_bounds[i], upper_bounds[i], alpha=0.2, label='Std of ' + label_list[i])\n","\n","plt.xticks(x_values)\n","plt.xlabel('Time step', fontsize=25)\n","# plt.ylabel('Bear SSIM', fontsize=25)\n","plt.ylim([0.96, ssim_max])\n","plt.grid(True)\n","# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=25)\n","plt.tight_layout()\n","\n","if VERBOSE:\n","    plt.savefig(directory + 'Plots/Bear_SSIM.pdf', format='pdf', bbox_inches='tight')\n","    print(\"Plot saved successfully.\")\n","\n","plt.show()\n"],"metadata":{"id":"znwF6YTo39zn"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f5gUGmA2tFRk"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def filter_outliers(data, threshold=1.5):\n","    \"\"\"Filters outliers using interquartile range method.\"\"\"\n","    q25, q75 = np.percentile(data, 25), np.percentile(data, 75)\n","    iqr = q75 - q25\n","    cut_off = iqr * threshold\n","    lower, upper = q25 - cut_off, q75 + cut_off\n","    return data[(data >= lower) & (data <= upper)]\n","\n","ssim_max = 1\n","\n","ssim_min_chimney = min([\n","    min(array.min() for array in ssim_4_pt_list_chimney[0][:]),\n","    min(array.min() for array in ssim_no_pt_list_chimney[0][:]),\n","    min(array.min() for array in ssim_3_t_list_chimney[0][:]),\n","    min(array.min() for array in ssim_2_p_list_chimney[0][:])\n","])\n","\n","ssim_3_t_arr = np.array(ssim_3_t_list_chimney)\n","y_value = ssim_3_t_list_chimney * 1.0\n","\n","# Filtering out outliers for each column\n","filtered_data = []\n","filtered_data.append([filter_outliers(np.array(ssim_4_pt_list_chimney)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(ssim_3_t_list_chimney)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(ssim_2_p_list_chimney)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(ssim_no_pt_list_chimney)[:, idx]) for idx in range(y_value.shape[1])])\n","\n","label_list = ['3T1P', '3T', '2P', 'No bar']\n","means_list = []\n","stds_list = []\n","for i in range(4):\n","    means = []\n","    stds = []\n","    for fd in filtered_data[i]:\n","        means.append(np.mean(fd))\n","        stds.append(np.std(fd))\n","    means_list.append(means)\n","    stds_list.append(stds)\n","\n","means_list = np.array(means_list)\n","stds_list = np.array(stds_list)\n","\n","x_values = range(1, 16)\n","upper_bounds = means_list + stds_list\n","lower_bounds = means_list - stds_list\n","\n","# Scatter plot for individual data points\n","plt.figure(figsize=(10, 6))\n","plt.rcParams.update({'font.size': 16})\n","plt.scatter([], [], color='red', s=10, alpha=0.5)\n","\n","for i in range(4):\n","    for idx, (x_val, column_data) in enumerate(zip(x_values, filtered_data[i])):\n","        plt.scatter([x_val] * len(column_data), column_data, s=10, alpha=0.5)\n","\n","    plt.plot(x_values, means_list[i], 'o-', label='Mean of ' + label_list[i])\n","    plt.fill_between(x_values, lower_bounds[i], upper_bounds[i], alpha=0.2, label='Std of ' + label_list[i])\n","\n","plt.xticks(x_values)\n","plt.xlabel('Time step', fontsize=25)\n","# plt.ylabel('Chimney SSIM', fontsize=25)\n","plt.ylim([0.96, ssim_max])\n","plt.grid(True)\n","# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=25)\n","plt.tight_layout()\n","\n","if VERBOSE:\n","    plt.savefig(directory + 'Plots/Chimney_SSIM.pdf', format='pdf', bbox_inches='tight')\n","    print(\"Plot saved successfully.\")\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dxa7NPlasq_K"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","ssim_max = 1\n","\n","ssim_min_ferguson = min([\n","    min(array.min() for array in ssim_4_pt_list_ferguson[0][:]),\n","    min(array.min() for array in ssim_no_pt_list_ferguson[0][:]),\n","    min(array.min() for array in ssim_3_t_list_ferguson[0][:]),\n","    min(array.min() for array in ssim_2_p_list_ferguson[0][:])\n","])\n","\n","ssim_3_t_arr = np.array(ssim_3_t_list_ferguson)\n","y_value = ssim_3_t_list_ferguson * 1.0\n","\n","# Filtering out outliers for each column\n","filtered_data = []\n","filtered_data.append([filter_outliers(np.array(ssim_4_pt_list_ferguson)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(ssim_3_t_list_ferguson)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(ssim_2_p_list_ferguson)[:, idx]) for idx in range(y_value.shape[1])])\n","filtered_data.append([filter_outliers(np.array(ssim_no_pt_list_ferguson)[:, idx]) for idx in range(y_value.shape[1])])\n","\n","label_list = ['3T1P', '3T', '2P', 'No bar']\n","means_list = []\n","stds_list = []\n","for i in range(4):\n","    means = []\n","    stds = []\n","    for fd in filtered_data[i]:\n","        means.append(np.mean(fd))\n","        stds.append(np.std(fd))\n","    means_list.append(means)\n","    stds_list.append(stds)\n","\n","means_list = np.array(means_list)\n","stds_list = np.array(stds_list)\n","\n","x_values = range(1, 16)\n","upper_bounds = means_list + stds_list\n","lower_bounds = means_list - stds_list\n","\n","# Scatter plot for individual data points\n","plt.figure(figsize=(10, 6))\n","plt.rcParams.update({'font.size': 16})\n","plt.scatter([], [], color='red', s=10, alpha=0.5)\n","\n","for i in range(4):\n","    for idx, (x_val, column_data) in enumerate(zip(x_values, filtered_data[i])):\n","        plt.scatter([x_val] * len(column_data), column_data, s=10, alpha=0.5)\n","\n","    plt.plot(x_values, means_list[i], 'o-', label='Mean of ' + label_list[i])\n","    plt.fill_between(x_values, lower_bounds[i], upper_bounds[i], alpha=0.2, label='Std of ' + label_list[i])\n","\n","plt.xticks(x_values)\n","plt.xlabel('Time step', fontsize=25)\n","# plt.ylabel('Ferguson SSIM', fontsize=25)\n","plt.ylim([0.96, ssim_max])\n","plt.grid(True)\n","# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=25)\n","plt.tight_layout()\n","\n","if VERBOSE:\n","    plt.savefig(directory + 'Plots/Ferguson_SSIM.pdf', format='pdf', bbox_inches='tight')\n","    print(\"Plot saved successfully.\")\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ppTtAkd81fPO"},"outputs":[],"source":[]},{"cell_type":"code","source":[],"metadata":{"id":"YuTedZcTus1U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W2SCXLJoxxel"},"source":["# plot inference speed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mGIrFOuVxxRN"},"outputs":[],"source":["import json\n","\n","with open(directory + 'Data/inference_speed_evaluation_data/fer_a100_conv_time_dic.json', 'r') as json_file:\n","    fer_a100_conv_time_dic = json.load(json_file)\n","\n","with open(directory + 'Data/inference_speed_evaluation_data/chimney_a100_conv_time_dic.json', 'r') as json_file:\n","    chimney_a100_conv_time_dic = json.load(json_file)\n","\n","with open(directory + 'Data/inference_speed_evaluation_data/bear_a100_conv_time_dic.json', 'r') as json_file:\n","    bear_a100_conv_time_dic = json.load(json_file)\n","\n","with open(directory + 'Data/inference_speed_evaluation_data/fer_ca_time_dic.json', 'r') as json_file:\n","    fer_ca_time_dic = json.load(json_file)\n","\n","with open(directory + 'Data/inference_speed_evaluation_data/bear_ca_time_dic.json', 'r') as json_file:\n","    bear_ca_time_dic = json.load(json_file)\n","\n","with open(directory + 'Data/inference_speed_evaluation_data/chimney_ca_time_dic.json', 'r') as json_file:\n","    chimney_ca_time_dic = json.load(json_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n7-qvvNFaKL5"},"outputs":[],"source":["def filter_outliers(data, threshold=1.5):\n","    \"\"\"Filters outliers using interquartile range method.\"\"\"\n","    q25, q75 = np.percentile(data, 25), np.percentile(data, 75)\n","    iqr = q75 - q25\n","    cut_off = iqr * threshold\n","    lower, upper = q25 - cut_off, q75 + cut_off\n","    return data[(data >= lower) & (data <= upper)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MLYhTZKCxNoP"},"outputs":[],"source":["sizes = [128, 256, 384, 512, 640, 768]\n","\n","filtered_fer_a100_conv = []\n","filtered_chimney_a100_conv = []\n","filtered_bear_a100_conv = []\n","\n","unfiltered_fer_a100_conv = []\n","unfiltered_chimney_a100_conv = []\n","unfiltered_bear_a100_conv = []\n","\n","filtered_fer_ca = []\n","filtered_bear_ca = []\n","filtered_chimney_ca = []\n","\n","unfiltered_fer_ca = []\n","unfiltered_bear_ca = []\n","unfiltered_chimney_ca = []\n","\n","for size in sizes:\n","    ind = size/128\n","    ca_ind = 3/26\n","    fer_a100_conv_time_dic[f'{size}'] = [element * ind for element in fer_a100_conv_time_dic[f'{size}']]\n","    chimney_a100_conv_time_dic[f'{size}'] = [element * ind for element in chimney_a100_conv_time_dic[f'{size}']]\n","    bear_a100_conv_time_dic[f'{size}'] = [element * ind for element in bear_a100_conv_time_dic[f'{size}']]\n","\n","    fer_ca_time_dic[f'{size}'] = [element * ind * ca_ind for element in fer_ca_time_dic[f'{size}']]\n","    bear_ca_time_dic[f'{size}'] = [element * ind * ca_ind for element in bear_ca_time_dic[f'{size}']]\n","    chimney_ca_time_dic[f'{size}'] = [element * ind * ca_ind for element in chimney_ca_time_dic[f'{size}']]\n","\n","    filtered_fer_a100_conv.append(filter_outliers(np.array(fer_a100_conv_time_dic[f'{size}'])*1.0))\n","    filtered_chimney_a100_conv.append(filter_outliers(np.array(chimney_a100_conv_time_dic[f'{size}'])*1.0))\n","    filtered_bear_a100_conv.append(filter_outliers(np.array(bear_a100_conv_time_dic[f'{size}'])*1.0))\n","\n","    unfiltered_fer_a100_conv.append(np.array(fer_a100_conv_time_dic[f'{size}'])*1.0)\n","    unfiltered_chimney_a100_conv.append(np.array(chimney_a100_conv_time_dic[f'{size}'])*1.0)\n","    unfiltered_bear_a100_conv.append(np.array(bear_a100_conv_time_dic[f'{size}'])*1.0)\n","\n","    # filtered_fer_a100_conv.append(np.array(fer_a100_conv_time_dic[f'{size}'])*1.0)\n","    # filtered_chimney_a100_conv.append(np.array(chimney_a100_conv_time_dic[f'{size}'])*1.0)\n","    # filtered_bear_a100_conv.append(np.array(bear_a100_conv_time_dic[f'{size}'])*1.0)\n","\n","    filtered_fer_ca.append(filter_outliers(np.array(fer_ca_time_dic[f'{size}'])*1.0))\n","    filtered_bear_ca.append(filter_outliers(np.array(bear_ca_time_dic[f'{size}'])*1.0))\n","    filtered_chimney_ca.append(filter_outliers(np.array(chimney_ca_time_dic[f'{size}'])*1.0))\n","\n","    unfiltered_fer_ca.append(np.array(fer_ca_time_dic[f'{size}'])*1.0)\n","    unfiltered_bear_ca.append(np.array(bear_ca_time_dic[f'{size}'])*1.0)\n","    unfiltered_chimney_ca.append(np.array(chimney_ca_time_dic[f'{size}'])*1.0)"]},{"cell_type":"code","source":["# Updated size arrays\n","sizes_all = [128, 256, 384, 512, 640, 768]\n","\n","mean_bear_a100 = [np.mean(fd) for fd in filtered_bear_a100_conv]\n","mean_chimney_a100 = [np.mean(fd) for fd in filtered_chimney_a100_conv]\n","mean_fer_a100 = [np.mean(fd) for fd in filtered_fer_a100_conv]\n","\n","mean_bear_ca = [np.mean(fd) for fd in filtered_bear_ca]\n","mean_chimney_ca = [np.mean(fd) for fd in filtered_chimney_ca]\n","mean_fer_ca = [np.mean(fd) for fd in filtered_fer_ca]\n","\n","# Calculate the standard deviations\n","std_bear_a100 = [np.std(fd) for fd in filtered_bear_a100_conv]\n","std_chimney_a100 = [np.std(fd) for fd in filtered_chimney_a100_conv]\n","std_fer_a100 = [np.std(fd) for fd in filtered_fer_a100_conv]\n","\n","std_bear_ca = [np.std(fd) for fd in filtered_bear_ca]\n","std_chimney_ca = [np.std(fd) for fd in filtered_chimney_ca]\n","std_fer_ca = [np.std(fd) for fd in filtered_fer_ca]\n"],"metadata":{"id":"tBofymcDtFLS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Setup plot\n","fig, ax1 = plt.subplots(figsize=(10, 6))\n","ax2 = ax1.twinx()  # Create a second y-axis\n","plt.rcParams.update({'font.size': 16})\n","\n","# Colors and labels for each series\n","colors = ['red', 'green', 'blue', 'maroon', 'darkolivegreen', 'gray']\n","labels = ['Bear ConvLSTM', 'Chimney ConvLSTM', 'Ferguson ConvLSTM', 'Bear CA', 'Chimney CA', 'Ferguson CA']\n","means = [mean_bear_a100, mean_chimney_a100, mean_fer_a100, mean_bear_ca, mean_chimney_ca, mean_fer_ca]\n","# stds = [std_bear_a100, std_chimney_a100, std_fer_a100, std_bear_ca, std_chimney_ca, std_fer_ca]  # Standard deviations\n","sizes_list = [sizes_all, sizes_all, sizes_all, sizes_all, sizes_all, sizes_all]\n","\n","# Define color for the CA CPU data\n","ca_colors = ['maroon', 'darkolivegreen', 'gray']\n","conv_colors = ['red', 'green', 'blue']\n","\n","# Plot GPU data on ax1 and CPU data on ax2 with mean, dots, lines, and standard deviation shading\n","for mean, color, label, sizes in zip(means[:-3], conv_colors, labels[:-3], sizes_list[:-3]):\n","    ax1.plot(sizes, mean, 'o-', label=f'{label} (Mean)', color=color)\n","    # ax1.fill_between(sizes, np.array(mean) - np.array(std), np.array(mean) + np.array(std), label=f'{label} (Std)', color=color, alpha=0.3)\n","\n","# CA CPU data\n","for mean, color, label, sizes in zip(means[-3:], ca_colors, labels[-3:], sizes_list[-3:]):\n","    ax2.plot(sizes, mean, 'o-', label=f'{label} (Mean)', color=color)\n","    # ax2.fill_between(sizes, np.array(mean) - np.array(std), np.array(mean) + np.array(std), label=f'{label} (Std)', color=color, alpha=0.3)\n","\n","ax1.set_xlabel('Resolution')\n","ax1.set_ylabel('Time for Conv Models (s)', color='black')\n","ax2.set_ylabel('Time for CA (s)', color='black')\n","\n","ax1.set_ylim(0, 0.2)\n","\n","ax1.set_xticks([128, 256, 384, 512, 640, 768])\n","ax1.set_xticklabels(['128', '256', '384', '512', '640', '768'])\n","\n","# Set legends\n","conv_handles, conv_labels = ax1.get_legend_handles_labels()\n","ca_handle, ca_label = ax2.get_legend_handles_labels()\n","ax1.legend(conv_handles, conv_labels, loc='upper left')\n","ax2.legend(ca_handle, ca_label, loc='upper right')\n","\n","ax1.grid(True)\n","fig.tight_layout()  # Adjust layout to make room for the legend\n","\n","# Save the plot if VERBOSE is defined and true\n","VERBOSE = True  # Define VERBOSE if not already defined\n","if VERBOSE:\n","    plt.savefig(directory + 'Plots/speed_comparison.pdf', format='pdf', bbox_inches='tight')\n","    print(\"Plot saved successfully.\")\n","\n","plt.show()\n"],"metadata":{"id":"zk90xBBpFMmg"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["1Txfo09mYcoI","W2SCXLJoxxel"],"authorship_tag":"ABX9TyOMwy1acaUNM3gIKBoh96RK"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}